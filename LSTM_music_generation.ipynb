{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM music generation",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amenimtibaa/LSTM_music_generation/blob/master/LSTM_music_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LW7KqPdLkJvl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Music Generation\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "0CkcEm-Pj0GT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.python.keras.layers import Input, LSTM, Bidirectional, Dense, Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
        "from keras.utils import np_utils\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "euA0nK6OjW70",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Connect to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tscL9ELbeUQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get the notes file from drive\n",
        "with open('/content/gdrive/My Drive/notes', 'rb') as filepath:\n",
        "  notes = pickle.load(filepath)\n",
        "n_vocab = len(set(notes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JU2hTzRResr3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def data_process(notes,n_vocab,verbose=False):\n",
        "  \n",
        "    \"\"\" Prepare the sequences used by the Neural Network (network input and output) \"\"\"\n",
        "    \n",
        "    sequence_length = 100\n",
        "\n",
        "    print(\"starting preparing data ...\")\n",
        "\n",
        "    # Get all pitch names\n",
        "      # P.S : A set is an unordered collection of items.Every element is unique (no duplicates)\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "\n",
        "    # Create a dictionary to map pitches to integers\n",
        "      # P.S : To get the integer encoding for position we use enumerate, return the integer + encoding\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    network_input = []\n",
        "    network_output = []\n",
        "\n",
        "    # Create input sequences and the corresponding outputs\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        network_output.append(note_to_int[sequence_out])\n",
        "\n",
        "    if (verbose):\n",
        "        print('you have ',len(note_to_int), ' distinct pitches')\n",
        "        print('network_input:   ', len(network_input))\n",
        "        print('network_output:   ', len(network_output))\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # Reshape the input into a format compatible with LSTM layers\n",
        "    network_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "\n",
        "    # Normalize input\n",
        "    network_input = network_input / float(n_vocab)\n",
        "    # One-hot encode the output\n",
        "    network_output = np_utils.to_categorical(network_output)\n",
        "\n",
        "    return network_input,network_output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZOLpWk0VG2N5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "network_input, network_output = data_process(notes,n_vocab,True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vG9HmAJ6gKH0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def create_network(network_input, n_vocab):\n",
        "  \n",
        "    \"\"\" create the structure of the neural network \"\"\"\n",
        "    \n",
        "    model = Sequential()\n",
        "    model.add(tf.keras.layers.LSTM(\n",
        "        512,\n",
        "        input_shape=(network_input.shape[1], network_input.shape[2]),\n",
        "        return_sequences=True\n",
        "    ))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.LSTM(512, return_sequences=True))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.LSTM(512))\n",
        "    model.add(tf.keras.layers.Dense(256))\n",
        "    model.add(tf.keras.layers.Dropout(0.3))\n",
        "    model.add(tf.keras.layers.Dense(n_vocab))\n",
        "    model.add(tf.keras.layers.Activation('softmax'))\n",
        "\n",
        "    model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
        "                  optimizer = tf.contrib.tpu.CrossShardOptimizer(tf.train.RMSPropOptimizer(learning_rate=0.0005)),\n",
        "                  metrics=['accuracy'])\n",
        "    #first learning rate was (0.01) but the acc was descreasing and the loss was increasing ==> this is why tuning parameters is important :)\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_9DOom7kn7k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = create_network(network_input, n_vocab)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FXp7wUjtt2GN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def convertToTPU(): \n",
        "  \n",
        "  \"\"\" Convert Keras model to TPU model \"\"\"\n",
        "  \n",
        "  # This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "  TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "  tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "  tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "      model,\n",
        "      strategy=tf.contrib.tpu.TPUDistributionStrategy(\n",
        "        tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-r0mwRQvUdIC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "convertToTPU()\n",
        "tpu_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRtmEWbYFNWE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()\n",
        "from google.colab import files\n",
        "\n",
        "def train(tpu_model, network_input, network_output):\n",
        "  \n",
        "    \"\"\" Training the TPU model \"\"\"\n",
        "\n",
        "    filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath,\n",
        "        monitor='loss',\n",
        "        verbose=0,\n",
        "        save_best_only=True,\n",
        "        mode='min'\n",
        "        # Save weights, every 10-epochs.\n",
        "        #period=10\n",
        "    )\n",
        "\n",
        "    callbacks_list = [checkpoint]\n",
        "    \n",
        "    history = tpu_model.fit(network_input, network_output, epochs=100, batch_size=128 * 8, callbacks=callbacks_list)\n",
        "    tpu_model.save_weights('./tpu_model.hdf5', overwrite=True)\n",
        "    \n",
        "    #download weight to local:\n",
        "    #files.download('tpu_model.hdf5')\n",
        "\n",
        "    #print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
        "    return history"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lujzbDXmImob",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history = train(tpu_model, network_input, network_output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CgxPpzNz6LMn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The prediction stage\n",
        "  # Once the model is trained, we recreate the network and we load the learned weights.\n",
        "\n",
        "inferencing_model = create_network(network_input, n_vocab)\n",
        "inferencing_model.load_weights('./tpu_model.h5')\n",
        "inferencing_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEnm0dgUZmNd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from pydrive.auth import GoogleAuth\n",
        "\n",
        "# Authenticate and create the PyDrive client\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CFK8qkwK6_yj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from music21 import instrument, note, stream, chord\n",
        "\n",
        "def prepare_sequences(notes, pitchnames, n_vocab):\n",
        "  \n",
        "    \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n",
        "    \n",
        "    # map between notes and integers and back\n",
        "    note_to_int = dict((note, number) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    sequence_length = 100\n",
        "    network_input = []\n",
        "    output = []\n",
        "    for i in range(0, len(notes) - sequence_length, 1):\n",
        "        sequence_in = notes[i:i + sequence_length]\n",
        "        sequence_out = notes[i + sequence_length]\n",
        "        network_input.append([note_to_int[char] for char in sequence_in])\n",
        "        output.append(note_to_int[sequence_out])\n",
        "\n",
        "    n_patterns = len(network_input)\n",
        "\n",
        "    # reshape the input into a format compatible with LSTM layers\n",
        "    normalized_input = np.reshape(network_input, (n_patterns, sequence_length, 1))\n",
        "    \n",
        "    # normalize input\n",
        "    normalized_input = normalized_input / float(n_vocab)\n",
        "\n",
        "    return (network_input, normalized_input)\n",
        "\n",
        "def generate_notes(model, network_input, pitchnames, n_vocab):\n",
        "  \n",
        "    \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n",
        "    \n",
        "    # pick a random sequence from the input as a starting point for the prediction\n",
        "    start = np.random.randint(0, len(network_input)-1)\n",
        "\n",
        "    int_to_note = dict((number, note) for number, note in enumerate(pitchnames))\n",
        "\n",
        "    pattern = network_input[start]\n",
        "    prediction_output = []\n",
        "\n",
        "    # generate 500 notes\n",
        "    for note_index in range(500):\n",
        "        prediction_input = np.reshape(pattern, (1, len(pattern), 1))\n",
        "        prediction_input = prediction_input / float(n_vocab)\n",
        "        prediction = model.predict(prediction_input, verbose=0)\n",
        "        index = np.argmax(prediction)\n",
        "        result = int_to_note[index]\n",
        "        prediction_output.append(result)\n",
        "        pattern.append(index)\n",
        "        pattern = pattern[1:len(pattern)]\n",
        "\n",
        "    return prediction_output\n",
        "  \n",
        "def create_midi(prediction_output):\n",
        "  \n",
        "    \"\"\" convert the predicted output to a midi file \"\"\"\n",
        "    \n",
        "    offset = 0\n",
        "    output_notes = []\n",
        "\n",
        "    # create note and chord objects based on the values generated by the model\n",
        "    for pattern in prediction_output:\n",
        "        # pattern is a chord\n",
        "        if ('.' in pattern) or pattern.isdigit():\n",
        "            notes_in_chord = pattern.split('.')\n",
        "            notes = []\n",
        "            for current_note in notes_in_chord:\n",
        "                new_note = note.Note(int(current_note))\n",
        "                new_note.storedInstrument = instrument.Piano()\n",
        "                notes.append(new_note)\n",
        "            new_chord = chord.Chord(notes)\n",
        "            new_chord.offset = offset\n",
        "            output_notes.append(new_chord)\n",
        "        # pattern is a note\n",
        "        else:\n",
        "            new_note = note.Note(pattern)\n",
        "            new_note.offset = offset\n",
        "            new_note.storedInstrument = instrument.Piano()\n",
        "            output_notes.append(new_note)\n",
        "\n",
        "        # increase offset each iteration so that notes do not stack\n",
        "        offset += 0.5\n",
        "\n",
        "    midi_stream = stream.Stream(output_notes)    \n",
        "    \n",
        "    # Create & upload a midi file in drive \n",
        "    uploaded = drive.CreateFile({'title': 'Midi_music.mid'})\n",
        "    midi_stream.write('midi', uploaded.SetContentString('Midi_music.mid'))\n",
        "    uploaded.Upload()\n",
        "    print('Uploaded file with ID {}'.format(uploaded.get('id')))\n",
        "    \n",
        "    # Download to local\n",
        "    #files.download('Midi_music.mid')\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ufTU2NLL79Uy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate():\n",
        "  \n",
        "    \"\"\" Generate a piano midi file \"\"\"\n",
        "\n",
        "    # Get all pitch names\n",
        "    pitchnames = sorted(set(item for item in notes))\n",
        "    n_vocab = len(set(notes))\n",
        "    network_input, normalized_input = prepare_sequences(notes, pitchnames, n_vocab)\n",
        "    model = create_network(normalized_input, n_vocab)\n",
        "    prediction_output = generate_notes(model, network_input, pitchnames, n_vocab)\n",
        "    create_midi(prediction_output)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rPFzmsRy8URW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "generate()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}